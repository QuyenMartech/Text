from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys
from functools import wraps
import functools
import time
import pandas as pd
import os
import random
import json
import requests
from datetime import datetime, timedelta
from urllib.parse import quote

class FacebookAdsLibrary:
    def __init__(self):
        self.chrome_options = Options()
        self.chrome_options.add_experimental_option("debuggerAddress", "127.0.0.1:9226")
        self.chrome_options.add_argument('--disable-gpu')
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--memory-pressure-off')
        self.chrome_options.add_argument('--disk-cache-size=1')
        self.chrome_options.add_argument('--media-cache-size=1')
        self.chrome_options.add_argument('--disable-applications-cache')
        self.service = Service()
        self.driver = None
        self.tracking_file = os.path.join("Downloads", "Ads Library Analysis", "tracking.json")
        self.tracking_data = self.load_tracking_data()
        self.current_keyword = None
        self.temp_data_buffer = []
        self.buffer_size = 100
        self.processed_ids = set()

    def load_tracking_data(self):
        print("Loading tracking data...")
        if os.path.exists(self.tracking_file):
            with open(self.tracking_file, 'r', encoding='utf-8') as f:
                print("Tracking data loaded successfully")
                return json.load(f)
        print("No existing tracking data found")
        return {}

    def save_tracking_data(self):
        print("Saving tracking data...")
        with open(self.tracking_file, 'w', encoding='utf-8') as f:
            json.dump(self.tracking_data, f, indent=4, ensure_ascii=False)
        print("Tracking data saved successfully")

    def load_processed_ids(self, output_path):
        if os.path.exists(output_path):
            df = pd.read_excel(output_path)
            return set(df['library_id'].tolist())
        return set()

    def flush_buffer_to_excel(self, output_path):
        if not self.temp_data_buffer:
            return

        print(f"Flushing {len(self.temp_data_buffer)} records to Excel...")
        columns = [
            'keyword', 'library_id', 'runtime', 'page_name', 'ad_status',
            'ads_using_content', 'content', 'Button_CTA', 'Link_CTA', 'has_video', 'video_url'
        ]

        new_df = pd.DataFrame(self.temp_data_buffer)
        
        if os.path.exists(output_path):
            with pd.ExcelWriter(output_path, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:
                start_row = writer.sheets['Sheet1'].max_row
                new_df.to_excel(writer, index=False, header=False, startrow=start_row)
        else:
            new_df = new_df[columns]
            new_df.to_excel(output_path, index=False)

        self.temp_data_buffer = []
        print("Buffer flushed successfully")
    
    def simulate_human_scroll(self, start_y, end_y, duration=1.0):
        """M√¥ ph·ªèng cu·ªôn chu·ªôt t·ª± nhi√™n c·ªßa ng∆∞·ªùi d√πng."""
        print(f"Simulating human scroll from {start_y} to {end_y}")
        steps = int(duration * 60)  # 60 b∆∞·ªõc m·ªói gi√¢y
        step_y = (end_y - start_y) / steps
        
        current_y = start_y
        for _ in range(steps):
            # Th√™m m·ªôt ch√∫t ng·∫´u nhi√™n v√†o m·ªói b∆∞·ªõc cu·ªôn
            random_offset = random.uniform(-1, 1)
            current_y += step_y + random_offset
            self.driver.execute_script(f"window.scrollTo(0, {current_y});")
            # Th√™m ƒë·ªô tr·ªÖ ng·∫´u nhi√™n gi·ªØa c√°c b∆∞·ªõc
            time.sleep(random.uniform(0.01, 0.03))
            
    def close_block_popup(self):
        try:
            # T√¨m button OK b·∫±ng aria-label v√† class ƒë·∫∑c tr∆∞ng
            popup = self.driver.find_element(By.XPATH, "//div[@aria-label='OK' and contains(@class, 'x1i10hfl')]")
            actions = ActionChains(self.driver)
            actions.click(popup).perform()
            time.sleep(1)
            return True
        except Exception as e:
            # Th√¥ng b√°o ƒë∆°n gi·∫£n v√† th√¢n thi·ªán h∆°n
            print("Kh√¥ng t√¨m th·∫•y popup c·∫ßn ƒë√≥ng - c√≥ th·ªÉ popup ch∆∞a xu·∫•t hi·ªán ho·∫∑c ƒë√£ ƒë∆∞·ª£c ƒë√≥ng tr∆∞·ªõc ƒë√≥")
            return False

    def parse_runtime(self, runtime_text):
        print(f"Parsing runtime text: {runtime_text}")
        try:
            # X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p c√≥ d·∫•u g·∫°ch ngang (-)
            if " - " in runtime_text:
                start_date = runtime_text.split(" - ")[0].strip()
            else:
                # Lo·∫°i b·ªè c√°c ph·∫ßn text kh√¥ng c·∫ßn thi·∫øt
                start_date = (runtime_text.replace("ƒê√£ b·∫Øt ƒë·∫ßu ch·∫°y ", "")
                                  .replace("v√†o ", "")
                                  .replace("Ng√†y b·∫Øt ƒë·∫ßu ch·∫°y: ", "")
                                  .replace("Started running on ", ""))

            # Lo·∫°i b·ªè ph·∫ßn th·ªùi gian ho·∫°t ƒë·ªông n·∫øu c√≥
            if "¬∑" in start_date:
                start_date = start_date.split("¬∑")[0].strip()

            # Th√™m x·ª≠ l√Ω ƒë·ªãnh d·∫°ng "dd MMM yyyy"
            try:
                if len(start_date.split()) == 3:
                    day, month, year = start_date.split()
                    # Chuy·ªÉn ƒë·ªïi th√°ng vi·∫øt t·∫Øt sang s·ªë
                    months = {
                        'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,
                        'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12
                    }
                    month_num = months.get(month, None)
                    if month_num:
                        return datetime(int(year), month_num, int(day))
            except:
                pass

            try:
                # Th·ª≠ parse theo ƒë·ªãnh d·∫°ng "MMM dd, yyyy"
                if "," in start_date:
                    return datetime.strptime(start_date, "%b %d, %Y")
            except:
                pass

            # X·ª≠ l√Ω ƒë·ªãnh d·∫°ng ti·∫øng Vi·ªát: "6 Th√°ng 12, 2024"
            if "Th√°ng" in start_date:
                date_parts = start_date.split()
                day = int(date_parts[0])
                month = int(date_parts[2].replace(',', ''))
                year = int(date_parts[3])
                return datetime(year, month, day)

            # X·ª≠ l√Ω ƒë·ªãnh d·∫°ng ti·∫øng Vi·ªát r√∫t g·ªçn: "6 thg 12, 2024"
            elif "thg" in start_date:
                return datetime.strptime(start_date, "%d thg %m, %Y")

            print(f"Could not parse date format: {start_date}")
            return None

        except Exception as e:
            print(f"Error parsing runtime: {e} for text: {runtime_text}")
            return None

    def setup_driver(self):
        print("Setting up Chrome driver...")
        try:
            self.driver = webdriver.Chrome(service=self.service, options=self.chrome_options)
            print("Chrome driver setup successful")
            return True
        except Exception as e:
            print(f"Error setting up driver: {e}")
            return False

    def extract_ad_data(self, ad_element, keyword):
                    print("Extracting ad data...")
                    ad_data = {'keyword': keyword}
                    
                    try:
                        try:
                            # Tr√≠ch xu·∫•t library_id theo th·∫ª div v√† class ch√≠nh x√°c
                            library_id_element = ad_element.find_element(
                                By.CSS_SELECTOR, "div.xt0e3qv div.x1rg5ohu.x67bb7w span.x8t9es0.xw23nyj.xo1l8bm.x63nzvj.x108nfp6.xq9mrsl.x1h4wwuj.xeuugli"
                            )
                            ad_data['library_id'] = library_id_element.text.replace("Library ID: ", "")
                            print(f"Extracted library ID: {ad_data['library_id']}")
                        except:
                            ad_data['library_id'] = "N/A"
                        
                        try:
                            # Tr√≠ch xu·∫•t runtime theo th·∫ª div ch·ª©a th√¥ng tin th·ªùi gian
                            runtime_element = ad_element.find_element(
                                By.CSS_SELECTOR, "div.x3nfvp2.x1e56ztr > span.x8t9es0.xw23nyj.xo1l8bm.x63nzvj.x108nfp6.xq9mrsl.x1h4wwuj.xeuugli:not(.x1emribx):not(.x117nqv4)"
                            )
                            ad_data['runtime'] = runtime_element.text
                            print(f"Extracted runtime: {ad_data['runtime']}")
                        except:
                            ad_data['runtime'] = "N/A"

                        try:
                            ad_data['page_name'] = ad_element.find_element(
                                By.XPATH, ".//a[contains(@class, 'xt0psk2')]//span"
                            ).text
                            print(f"Extracted page name: {ad_data['page_name']}")
                        except:
                            ad_data['page_name'] = "N/A"
                        
                        try:
                            ad_data['ad_status'] = ad_element.find_element(
                                By.CLASS_NAME, "x117nqv4"
                            ).text
                            print(f"Extracted ad status: {ad_data['ad_status']}")
                        except:
                            ad_data['ad_status'] = "N/A"

                        try:
                            versions_text = ad_element.find_element(
                                By.XPATH, ".//span[contains(@class, 'x1fvot60')]//strong"
                            ).text
                            ad_data['ads_using_content'] = versions_text
                            print(f"Extracted ads using content: {ad_data['ads_using_content']}")
                        except:
                            ad_data['ads_using_content'] = "N/A"
                        
                        try:
                            ad_data['content'] = ad_element.find_element(
                                By.CLASS_NAME, "_7jyr"
                            ).text
                            print("Extracted ad content")
                        except:
                            ad_data['content'] = "N/A"
                        
                        try:
                            # T√¨m t·∫•t c·∫£ c√°c button CTA
                            cta_elements = ad_element.find_elements(
                                By.XPATH, ".//div[contains(@class, 'x8t9es0') and contains(@class, 'xuxw1ft') and contains(@class, 'x10wlt62')]"
                            )
                            # L·∫•y text c·ªßa button cu·ªëi c√πng
                            if len(cta_elements) > 0:
                                ad_data['Button_CTA'] = cta_elements[-1].text
                            else:
                                ad_data['Button_CTA'] = "None"
                            print(f"Extracted CTA button: {ad_data['Button_CTA']}")
                        except:
                            ad_data['Button_CTA'] = "None"
                        
                        try:
                            link_cta_elements = ad_element.find_elements(
                                By.XPATH, ".//div[contains(@class, 'x1iyjqo2') and contains(@class, 'xw3qccf')]//div[@class='_4ik4 _4ik5']"
                            )
                            # L·∫•y text t·ª´ c√°c ph·∫ßn t·ª≠ kh√¥ng r·ªóng
                            cta_texts = [elem.text for elem in link_cta_elements if elem.text.strip()]
                            
                            # K·∫øt h·ª£p c√°c text t√¨m ƒë∆∞·ª£c
                            ad_data['Link_CTA'] = ' | '.join(cta_texts)
                            print(f"Extracted Link CTA: {ad_data['Link_CTA']}")
                        except:
                            ad_data['Link_CTA'] = "None" 
                            print("No Link CTA found")
                        
                        try:
                            video = ad_element.find_element(By.TAG_NAME, "video")
                            ad_data['has_video'] = True
                            ad_data['video_url'] = video.get_attribute('src')
                            print("Found video content")
                        except:
                            ad_data['has_video'] = False
                            ad_data['video_url'] = "N/A"
                            
                            
                    except Exception as e:
                        print(f"Error extracting data: {e}")
                        
                    return ad_data

    def should_continue_scrolling(self, runtime_text, target_date):
        print(f"Checking if should continue scrolling for runtime: {runtime_text}")
        if not runtime_text or runtime_text == "N/A":
            return True
            
        runtime_date = self.parse_runtime(runtime_text)
        if not runtime_date:
            return True
            
        should_continue = runtime_date >= target_date
        print(f"Should continue scrolling: {should_continue}")
        return should_continue

    def scroll_and_extract(self, output_path):
        print("Starting scroll and extract process...")
        
        self.close_block_popup()  # Ki·ªÉm tra v√† ƒë√≥ng popup
        scroll_pause_time = random.uniform(3, 5)  # Th·ªùi gian d·ª´ng ng·∫´u nhi√™n
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        no_new_content_count = 0
        max_no_new_content = 8
        
        # Load existing IDs at start
        self.processed_ids = self.load_processed_ids(output_path)
        print(f"Loaded {len(self.processed_ids)} previously processed ads")

        target_date = None
        if self.current_keyword in self.tracking_data:
            first_runtime = datetime.strptime(self.tracking_data[self.current_keyword]['first_runtime'], "%Y-%m-%d")
            target_date = first_runtime - timedelta(days=60)
            print(f"Target date set to: {target_date}")
        
        # Theo d√µi ph·∫ßn t·ª≠ cu·ªëi c√πng ƒë√£ x·ª≠ l√Ω
        last_processed_element = None
        
        while True:
            try:
                # Ki·ªÉm tra v√† ƒë√≥ng popup tr∆∞·ªõc khi scroll
                self.close_block_popup()                
                
                print("Waiting for ad elements to load...")
                time.sleep(random.uniform(3, 5))
                
                # L·∫•y c√°c th√¥ng s·ªë cu·ªôn trang
                current_height = self.driver.execute_script("return document.body.scrollHeight")
                viewport_height = self.driver.execute_script("return window.innerHeight")
                current_scroll = self.driver.execute_script("return window.pageYOffset")
                
                # T√≠nh kho·∫£ng c√°ch c√≤n l·∫°i c√≥ th·ªÉ cu·ªôn
                remaining_scroll = current_height - current_scroll - viewport_height
                
                # Lu√¥n ƒë·∫£m b·∫£o c√≥ m·ªôt kho·∫£ng cu·ªôn t·ªëi thi·ªÉu
                scroll_distance = max(
                    min(viewport_height * random.uniform(0.5, 1.5),
                        remaining_scroll + viewport_height * 0.2),  # Th√™m m·ªôt ch√∫t d∆∞ ƒë·ªÉ ƒë·∫£m b·∫£o lu√¥n c√≥ th·ªÉ cu·ªôn
                    viewport_height * 0.2  # Kho·∫£ng cu·ªôn t·ªëi thi·ªÉu
                )
                
                # Th·ª±c hi·ªán cu·ªôn v·ªõi kho·∫£ng c√°ch ƒë√£ t√≠nh
                scroll_times = random.randint(1, 3)
                per_scroll_distance = scroll_distance / scroll_times
                current_position = current_scroll
                
                for i in range(scroll_times):
                
                    # Ki·ªÉm tra v√† ƒë√≥ng popup tr∆∞·ªõc m·ªói l·∫ßn scroll nh·ªè
                    self.close_block_popup()                
                    next_position = current_position + per_scroll_distance
                    next_position += random.uniform(-50, 50)
                    next_position = min(next_position, current_height - viewport_height * 0.5)
                    next_position = max(next_position, current_position)
                    
                    self.simulate_human_scroll(
                        current_position,
                        next_position,
                        duration=random.uniform(0.8, 1.5)
                    )
                    
                    current_position = next_position
                    if i < scroll_times - 1:
                        time.sleep(random.uniform(1, 2))
                        
                    # Ki·ªÉm tra v√† ƒë√≥ng popup sau m·ªói l·∫ßn scroll nh·ªè
                    self.close_block_popup()                        
                
                # T√¨m t·∫•t c·∫£ c√°c th·∫ª div ch·ª©a qu·∫£ng c√°o
                ad_elements = WebDriverWait(self.driver, 10).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.xh8yej3"))
                )
                
                # X√°c ƒë·ªãnh v·ªã tr√≠ b·∫Øt ƒë·∫ßu qu√©t
                start_index = 0
                if last_processed_element:
                    try:
                        start_index = ad_elements.index(last_processed_element) + 1
                    except ValueError:
                        start_index = 0
                
                new_ads_processed = 0
                
                # Ch·ªâ x·ª≠ l√Ω c√°c ph·∫ßn t·ª≠ m·ªõi
                for ad_element in ad_elements[start_index:]:
                    try:
                        library_id = None
                        try:
                            library_id_element = ad_element.find_element(
                                By.XPATH, ".//span[contains(text(),'Library ID:')]"
                            )
                            library_id = library_id_element.text.replace("Library ID: ", "")
                        except:
                            continue
                        
                        if library_id and library_id not in self.processed_ids:
                            print(f"Processing new ad: {library_id}")
                            ad_data = self.extract_ad_data(ad_element, self.current_keyword)
                            self.processed_ids.add(library_id)
                            new_ads_processed += 1
                            
                            if not target_date and ad_data['runtime'] != "N/A":
                                runtime_date = self.parse_runtime(ad_data['runtime'])
                                if runtime_date:
                                    self.tracking_data[self.current_keyword] = {
                                        'first_runtime': runtime_date.strftime("%Y-%m-%d"),
                                        'target_date': (runtime_date - timedelta(days=60)).strftime("%Y-%m-%d")
                                    }
                                    self.save_tracking_data()
                                    target_date = runtime_date - timedelta(days=60)
                                    print(f"Updated target date to: {target_date}")
                            
                            if target_date and not self.should_continue_scrolling(ad_data['runtime'], target_date):
                                print(f"Reached target date for keyword '{self.current_keyword}'")
                                self.flush_buffer_to_excel(output_path)
                                return
                            
                            self.temp_data_buffer.append(ad_data)
                            if len(self.temp_data_buffer) >= self.buffer_size:
                                self.flush_buffer_to_excel(output_path)                       
                            
                            # C·∫≠p nh·∫≠t ph·∫ßn t·ª≠ cu·ªëi c√πng ƒë√£ x·ª≠ l√Ω
                            last_processed_element = ad_element
                                                       
                    
                    except Exception as e:
                        print(f"Error processing ad element: {e}")
                        continue
                
                if new_ads_processed > 0:
                    print(f"Successfully processed {new_ads_processed} new ads")
                    no_new_content_count = 0  # Reset counter ch·ªâ khi c√≥ ads m·ªõi
                else:
                    no_new_content_count += 1
                    print(f"No new content found. Count: {no_new_content_count}")
                    
                if no_new_content_count >= max_no_new_content:
                    print("Reached maximum attempts without new content")
                    self.flush_buffer_to_excel(output_path)
                    return
                    
                # Ki·ªÉm tra v√† ƒë√≥ng popup sau khi scroll ƒë·∫øn cu·ªëi trang
                self.close_block_popup()
                
                print("Scrolling to bottom of page...")
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                print(f"Waiting for {scroll_pause_time} seconds...")
                time.sleep(scroll_pause_time)
                print("Adding random delay...")
                time.sleep(random.uniform(0.5, 1.5))
                
                # Ki·ªÉm tra v√† ƒë√≥ng popup sau khi scroll ƒë·∫øn cu·ªëi trang
                self.close_block_popup()                
                
                new_height = self.driver.execute_script("return document.body.scrollHeight")
                
                # Ki·ªÉm tra n·∫øu ƒë√£ ƒë·∫øn cu·ªëi trang
                if new_height == last_height:
                    print("Reached end of page")
                    self.flush_buffer_to_excel(output_path)
                    return
                    
                last_height = new_height
                
            except Exception as e:
                print(f"Error during scrolling: {e}")
                print("Waiting 5 seconds before retrying...")
                time.sleep(5)
                continue

    def process_keyword(self, keyword, output_path):
        try:
            print(f"\nProcessing keyword: {keyword}")
            self.current_keyword = keyword
            
            # Check if keyword is already completed
            if keyword in self.tracking_data and 'completed' in self.tracking_data[keyword]:
                print(f"Keyword '{keyword}' already completed. Skipping...")
                return
                
            encoded_keyword = quote(keyword)
            url = f"https://www.facebook.com/ads/library/?active_status=all&ad_type=all&content_languages[0]=en&country=US&is_targeted_country=false&media_type=video&q={encoded_keyword}&search_type=keyword_unordered"
            
            print(f"Navigating to URL: {url}")
            self.driver.get(url)
            self.close_block_popup()  # Ki·ªÉm tra v√† ƒë√≥ng popup
            print("Waiting 5 seconds for page load...")
            time.sleep(5)
            
            self.close_block_popup()  # Ki·ªÉm tra v√† ƒë√≥ng popup
            
            self.scroll_and_extract(output_path)
            
            # Mark keyword as completed
            if keyword not in self.tracking_data:
                self.tracking_data[keyword] = {}
            self.tracking_data[keyword]['completed'] = True
            self.save_tracking_data()
            
            # Send completion report to Telegram
            self.send_keyword_completion_report(output_path)
            
            print(f"Completed processing keyword '{keyword}'")
            
        except Exception as e:
            print(f"Error processing keyword '{keyword}': {e}")
        
    def process_keyword_files(self):
        print("Starting to process keyword files...")
        try:
            ads_library_dir = os.path.join("Downloads", "Ads Library Analysis")
            txt_files = [f for f in os.listdir(ads_library_dir) if f.endswith('.txt')]
            
            print(f"Found {len(txt_files)} text files to process")
            for txt_file in txt_files:
                txt_path = os.path.join(ads_library_dir, txt_file)
                output_path = os.path.join(ads_library_dir, f"{os.path.splitext(txt_file)[0]}_results.xlsx")
                
                print(f"\nProcessing file: {txt_file}")
                with open(txt_path, 'r', encoding='utf-8') as f:
                    keywords = [line.strip() for line in f if line.strip()]
                
                print(f"Found {len(keywords)} keywords in {txt_file}")
                for keyword in keywords:
                    print(f"\nProcessing keyword: {keyword}")
                    self.process_keyword(keyword, output_path)
                    
                    print("Waiting 2 seconds before next keyword...")
                    time.sleep(random.uniform(1, 3)) 
                
        except Exception as e:
            print(f"Error processing keyword files: {e}")
        
        try:
            response = requests.post(url, json={
                "chat_id": chat_id,
                "text": message,
                "parse_mode": "HTML"
            })
            if response.status_code != 200:
                print(f"Failed to send Telegram message: {response.text}")
        except Exception as e:
            print(f"Error sending Telegram message: {e}")

    def get_excel_row_count(self, output_path):
        """Get the number of rows in Excel file for current keyword."""
        try:
            if os.path.exists(output_path):
                df = pd.read_excel(output_path)
                return len(df[df['keyword'] == self.current_keyword])
            return 0
        except Exception as e:
            print(f"Error counting Excel rows: {e}")
            return 0

    def send_keyword_completion_report(self, output_path):
        """Send completion report for current keyword to Telegram."""
        try:
            if self.current_keyword in self.tracking_data:
                data = self.tracking_data[self.current_keyword]
                first_runtime = datetime.strptime(data['first_runtime'], "%Y-%m-%d")
                
                # Get the last runtime from Excel
                df = pd.read_excel(output_path)
                keyword_data = df[df['keyword'] == self.current_keyword]
                if not keyword_data.empty:
                    last_runtime_str = keyword_data['runtime'].iloc[-1]
                    last_runtime = self.parse_runtime(last_runtime_str)
                    last_runtime_str = last_runtime.strftime("%Y-%m-%d") if last_runtime else "Unknown"
                else:
                    last_runtime_str = "Unknown"
                
                row_count = self.get_excel_row_count(output_path)
                
                message = (
                    f"üìä Keyword Report: <b>{self.current_keyword}</b>\n\n"
                    f"üìÖ First data: {data['first_runtime']}\n"
                    f"üéØ Target date: {data['target_date']}\n"
                    f"üõë Last data: {last_runtime_str}\n"
                    f"üìù Total ads found: {row_count}"
                )
                
                self.send_telegram_message(message)
                
        except Exception as e:
            print(f"Error sending completion report: {e}")

    def close(self):
        print("Closing browser...")
        if self.driver:
            self.driver.quit()
        print("Browser closed successfully")

def main():
    print("Starting Facebook Ads Library Scraper...")
    os.makedirs(os.path.join("Downloads", "Ads Library Analysis"), exist_ok=True)
    print("Created necessary directories")

    scraper = FacebookAdsLibrary()
    print("Initialized scraper")

    if not scraper.setup_driver():
        print("Failed to setup driver. Exiting...")
        return

    try:
        scraper.process_keyword_files()
    finally:
        scraper.close()

if __name__ == "__main__":
    main()
